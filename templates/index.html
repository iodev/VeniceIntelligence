{% extends "base.html" %}

{% block content %}
<div class="row">
    <div class="col-md-9">
        <ul class="nav nav-tabs mb-3" id="agentTabs" role="tablist">
            <li class="nav-item" role="presentation">
                <button class="nav-link active" id="chat-tab" data-bs-toggle="tab" data-bs-target="#chatTab" 
                        type="button" role="tab" aria-controls="chatTab" aria-selected="true">
                    <i class="bi bi-chat-dots me-2"></i>Chat
                </button>
            </li>
            <li class="nav-item" role="presentation">
                <button class="nav-link" id="image-tab" data-bs-toggle="tab" data-bs-target="#imageTab" 
                        type="button" role="tab" aria-controls="imageTab" aria-selected="false">
                    <i class="bi bi-image me-2"></i>Generate Images
                </button>
            </li>
        </ul>
        
        <div class="tab-content" id="agentTabsContent">
            <!-- Chat Tab -->
            <div class="tab-pane fade show active" id="chatTab" role="tabpanel" aria-labelledby="chat-tab">
                <div class="card mb-4">
                    <div class="card-header d-flex justify-content-between align-items-center">
                        <h5 class="mb-0">
                            <i class="bi bi-chat-dots me-2"></i>
                            Chat with Agent
                        </h5>
                        <button class="btn btn-sm btn-outline-secondary" id="settingsBtn" data-bs-toggle="modal" data-bs-target="#settingsModal">
                            <i class="bi bi-gear"></i> Settings
                        </button>
                    </div>
                    <div class="card-body">
                        <div id="chatHistory" class="chat-history mb-3">
                            <div class="system-message">
                                <p><strong>üèõÔ∏è Venice.ai AI Agent</strong> - Multi-provider routing with intelligent cost optimization. Venice.ai models are prioritized, with smart fallback to Anthropic and Perplexity when optimal. How can I help you today?</p>
                            </div>
                        </div>
                        
                        <div class="mb-2">
                            <div class="query-type-selector btn-group" role="group" aria-label="Query type">
                                <input type="radio" class="btn-check" name="queryType" id="textQuery" value="text" checked>
                                <label class="btn btn-outline-secondary" for="textQuery">
                                    <i class="bi bi-chat-text"></i> Text
                                </label>
                                
                                <input type="radio" class="btn-check" name="queryType" id="codeQuery" value="code">
                                <label class="btn btn-outline-secondary" for="codeQuery">
                                    <i class="bi bi-code-square"></i> Code
                                </label>
                                
                                <input type="radio" class="btn-check" name="queryType" id="imageQuery" value="image">
                                <label class="btn btn-outline-secondary" for="imageQuery">
                                    <i class="bi bi-image"></i> Image
                                </label>
                            </div>
                            <small class="text-muted ms-2">Select the type of your query</small>
                        </div>
                        
                        <div class="mb-3">
                            <label for="modelSelect" class="form-label">
                                <i class="bi bi-cpu"></i> AI Model
                            </label>
                            <select id="modelSelect" class="form-select">
                                <option value="auto" selected>ü§ñ Smart Routing (Venice.ai Primary)</option>
                                <optgroup label="üèõÔ∏è Venice.ai Models (Primary Provider)">
                                    <option value="mistral-31-24b">Mistral 3.1 24B - Fast & Accurate</option>
                                    <option value="llama-3.2-3b">Llama 3.2 3B - Lightweight</option>
                                    <option value="llama-3.3-70b">Llama 3.3 70B - Most Powerful</option>
                                </optgroup>
                                <optgroup label="üîÑ Fallback Providers">
                                    <option value="claude-3-5-sonnet-20241022">Claude 3.5 Sonnet (Anthropic)</option>
                                    <option value="llama-3.1-sonar-small-128k-online">Llama Sonar Small (Perplexity)</option>
                                    <option value="llama-3.1-sonar-large-128k-online">Llama Sonar Large (Perplexity)</option>
                                </optgroup>
                            </select>
                            <small class="text-muted">Venice.ai provides primary AI models with intelligent routing to other providers when needed</small>
                        </div>
                        
                        <div class="input-group">
                            <textarea id="userInput" class="form-control" placeholder="Type your message here..." rows="4"></textarea>
                            <button id="sendBtn" class="btn btn-primary">
                                <i class="bi bi-send"></i> Send
                            </button>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Image Generation Tab -->
            <div class="tab-pane fade" id="imageTab" role="tabpanel" aria-labelledby="image-tab">
                <div class="card mb-4">
                    <div class="card-header d-flex justify-content-between align-items-center">
                        <h5 class="mb-0">
                            <i class="bi bi-image me-2"></i>
                            Generate Images
                        </h5>
                    </div>
                    <div class="card-body">
                        <form id="imageGenForm">
                            <div class="mb-3">
                                <label for="imagePrompt" class="form-label">Image Description</label>
                                <textarea id="imagePrompt" class="form-control" rows="3" 
                                          placeholder="Describe the image you want to generate..."></textarea>
                            </div>
                            
                            <div class="row mb-3">
                                <div class="col-md-6">
                                    <label for="imageModel" class="form-label">Image Model</label>
                                    <select id="imageModel" class="form-select">
                                        <option value="stable-diffusion-xl-1024-v1-0">Stable Diffusion XL</option>
                                        <!-- More options will be loaded dynamically -->
                                    </select>
                                </div>
                                
                                <div class="col-md-3">
                                    <label for="imageSize" class="form-label">Size</label>
                                    <select id="imageSize" class="form-select">
                                        <option value="1024x1024">1024x1024</option>
                                        <option value="896x1152">896x1152</option>
                                        <option value="1152x896">1152x896</option>
                                        <option value="768x768">768x768</option>
                                    </select>
                                </div>
                                
                                <div class="col-md-3">
                                    <label for="numImages" class="form-label">Count</label>
                                    <select id="numImages" class="form-select">
                                        <option value="1">1 image</option>
                                        <option value="2">2 images</option>
                                        <option value="4">4 images</option>
                                    </select>
                                </div>
                            </div>
                            
                            <div class="d-grid">
                                <button type="submit" id="generateBtn" class="btn btn-primary">
                                    <i class="bi bi-brush"></i> Generate Image
                                </button>
                            </div>
                        </form>
                        
                        <div id="imageResults" class="mt-4">
                            <!-- Generated images will appear here -->
                        </div>
                        
                        <div id="imageLoading" class="text-center my-5 d-none">
                            <div class="spinner-border text-primary" role="status">
                                <span class="visually-hidden">Generating image...</span>
                            </div>
                            <p class="mt-2">Creating your image...</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="col-md-3">
        <div class="card mb-4">
            <div class="card-header">
                <h5 class="mb-0">
                    <i class="bi bi-graph-up me-2"></i>
                    Model Performance
                </h5>
            </div>
            <div class="card-body">
                <div id="modelStats" class="model-stats">
                    <div class="text-center py-4">
                        <div class="spinner-border text-secondary" role="status">
                            <span class="visually-hidden">Loading...</span>
                        </div>
                        <p class="mt-2">Loading model data...</p>
                    </div>
                </div>
            </div>
        </div>

        <div class="card">
            <div class="card-header">
                <h5 class="mb-0">
                    <i class="bi bi-info-circle me-2"></i>
                    Agent Info
                </h5>
            </div>
            <div class="card-body">
                <p><strong>Current Model:</strong> <span id="currentModel">Loading...</span></p>
                <p><strong>System Prompt:</strong> <span id="systemPromptDisplay" class="text-muted fst-italic">Default</span></p>
                <hr>
                <div class="d-grid">
                    <button id="resetMemoryBtn" class="btn btn-outline-danger">
                        <i class="bi bi-trash"></i> Reset Memory
                    </button>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Settings Modal -->
<div class="modal fade" id="settingsModal" tabindex="-1" aria-labelledby="settingsModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="settingsModalLabel">Agent Settings</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <div class="mb-3">
                    <label for="systemPrompt" class="form-label">System Prompt</label>
                    <textarea class="form-control" id="systemPrompt" rows="5">You are a helpful AI assistant.</textarea>
                    <div class="form-text">Define the agent's purpose and behavior.</div>
                </div>
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cancel</button>
                <button type="button" class="btn btn-primary" id="saveSettingsBtn">Save Settings</button>
            </div>
        </div>
    </div>
</div>
{% endblock %}

{% block scripts %}
<script>
document.addEventListener('DOMContentLoaded', function() {
    // Elements
    const chatHistory = document.getElementById('chatHistory');
    const userInput = document.getElementById('userInput');
    const sendBtn = document.getElementById('sendBtn');
    const systemPrompt = document.getElementById('systemPrompt');
    const systemPromptDisplay = document.getElementById('systemPromptDisplay');
    const saveSettingsBtn = document.getElementById('saveSettingsBtn');
    const resetMemoryBtn = document.getElementById('resetMemoryBtn');
    const currentModelDisplay = document.getElementById('currentModel');
    const modelStats = document.getElementById('modelStats');
    
    // Default system prompt
    let currentSystemPrompt = "You are a helpful AI assistant.";
    systemPrompt.value = currentSystemPrompt;
    systemPromptDisplay.textContent = "You are a helpful AI assistant.";

    // Load model stats
    loadModelStats();
    
    // Event listeners
    sendBtn.addEventListener('click', sendMessage);
    userInput.addEventListener('keydown', function(e) {
        if (e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault();
            sendMessage();
        }
    });
    
    saveSettingsBtn.addEventListener('click', saveSettings);
    resetMemoryBtn.addEventListener('click', resetMemory);
    
    // Functions
    function sendMessage() {
        const query = userInput.value.trim();
        if (!query) return;
        
        // Get selected query type and model
        const queryType = document.querySelector('input[name="queryType"]:checked').value;
        const selectedModel = document.getElementById('modelSelect').value;
        
        // Add user message to chat
        addMessageToChat('user', query);
        
        // Clear input
        userInput.value = '';
        
        // Use streaming for better UX with long responses
        const useStreaming = true;
        
        if (useStreaming) {
            // Add streaming response container
            const messageDiv = document.createElement('div');
            messageDiv.className = 'assistant-message';
            messageDiv.innerHTML = `<p class="streaming-response"></p>`;
            chatHistory.appendChild(messageDiv);
            
            const responseElement = messageDiv.querySelector('.streaming-response');
            
            // Add initial typing indicator
            responseElement.innerHTML = `
                <div class="typing-indicator">
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            `;
            
            chatHistory.scrollTop = chatHistory.scrollHeight;
            
            // Connect to streaming endpoint with query type and model
            const eventSource = new EventSource(`/chat?stream=true&query=${encodeURIComponent(query)}&system_prompt=${encodeURIComponent(currentSystemPrompt)}&query_type=${encodeURIComponent(queryType)}&model_id=${encodeURIComponent(selectedModel)}`);
            
            let accumulatedResponse = '';
            let currentModel = '';
            
            eventSource.onmessage = function(event) {
                const data = JSON.parse(event.data);
                
                if (data.type === 'start') {
                    // Connection established, model information
                    currentModel = data.model_used;
                    // Clear typing indicator
                    responseElement.innerHTML = '';
                } 
                else if (data.type === 'chunk') {
                    // Append new text chunk
                    accumulatedResponse += data.chunk;
                    responseElement.innerHTML = formatMessage(accumulatedResponse);
                    chatHistory.scrollTop = chatHistory.scrollHeight;
                } 
                else if (data.type === 'end') {
                    // Streaming complete
                    eventSource.close();
                    
                    // Update model display
                    if (currentModel) {
                        currentModelDisplay.textContent = formatModelName(currentModel);
                    }
                    
                    // Refresh model stats
                    loadModelStats();
                } 
                else if (data.type === 'error') {
                    // Handle error
                    eventSource.close();
                    responseElement.innerHTML = `<span class="text-danger">Error: ${data.error}</span>`;
                }
            };
            
            eventSource.onerror = function() {
                eventSource.close();
                if (accumulatedResponse === '') {
                    responseElement.innerHTML = `<span class="text-danger">Error: Connection failed</span>`;
                }
            };
        } 
        else {
            // Fallback to non-streaming for older browsers
            
            // Add loading indicator
            const loadingDiv = document.createElement('div');
            loadingDiv.className = 'assistant-message loading';
            loadingDiv.innerHTML = `
                <div class="typing-indicator">
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            `;
            chatHistory.appendChild(loadingDiv);
            chatHistory.scrollTop = chatHistory.scrollHeight;
            
            // Send to backend
            fetch('/chat', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    query: query,
                    system_prompt: currentSystemPrompt,
                    query_type: queryType,
                    model_id: selectedModel,
                    stream: false
                })
            })
            .then(response => response.json())
            .then(data => {
                // Remove loading indicator
                chatHistory.removeChild(loadingDiv);
                
                if (data.error) {
                    addMessageToChat('system', `Error: ${data.error}`);
                } else {
                    addMessageToChat('assistant', data.response);
                    // Update model display if needed
                    if (data.model_used) {
                        currentModelDisplay.textContent = formatModelName(data.model_used);
                    }
                    // Refresh model stats
                    loadModelStats();
                }
            })
            .catch(error => {
                // Remove loading indicator
                chatHistory.removeChild(loadingDiv);
                addMessageToChat('system', `Error: ${error.message}`);
            });
        }
    }
    
    function addMessageToChat(role, content) {
        const messageDiv = document.createElement('div');
        messageDiv.className = `${role}-message`;
        
        // Format message with markdown-like syntax
        const formattedContent = formatMessage(content);
        
        // Add message content
        messageDiv.innerHTML = `<p>${formattedContent}</p>`;
        
        // Add to chat history
        chatHistory.appendChild(messageDiv);
        
        // Scroll to bottom
        chatHistory.scrollTop = chatHistory.scrollHeight;
    }
    
    function formatMessage(content) {
        // Simple formatting for code blocks
        content = content.replace(/```([\s\S]*?)```/g, '<pre><code>$1</code></pre>');
        
        // Bold text
        content = content.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
        
        // Italic text
        content = content.replace(/\*(.*?)\*/g, '<em>$1</em>');
        
        // Line breaks
        content = content.replace(/\n/g, '<br>');
        
        return content;
    }
    
    function saveSettings() {
        const newSystemPrompt = systemPrompt.value.trim();
        if (!newSystemPrompt) {
            alert('System prompt cannot be empty');
            return;
        }
        
        // Send to backend
        fetch('/api/set_system_prompt', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                system_prompt: newSystemPrompt
            })
        })
        .then(response => response.json())
        .then(data => {
            if (data.error) {
                alert(`Error: ${data.error}`);
            } else {
                currentSystemPrompt = newSystemPrompt;
                systemPromptDisplay.textContent = truncateText(newSystemPrompt, 50);
                
                // Close modal
                const modal = bootstrap.Modal.getInstance(document.getElementById('settingsModal'));
                modal.hide();
                
                // Add confirmation message
                addMessageToChat('system', 'System prompt updated. The agent will adapt to this new purpose.');
            }
        })
        .catch(error => {
            alert(`Error: ${error.message}`);
        });
    }
    
    function resetMemory() {
        if (!confirm('Are you sure you want to reset the agent\'s memory? This cannot be undone.')) {
            return;
        }
        
        fetch('/api/reset_memory', {
            method: 'POST'
        })
        .then(response => response.json())
        .then(data => {
            if (data.error) {
                alert(`Error: ${data.error}`);
            } else {
                addMessageToChat('system', 'Memory reset successfully. The agent has forgotten previous interactions.');
            }
        })
        .catch(error => {
            alert(`Error: ${error.message}`);
        });
    }
    
    function loadModelStats() {
        fetch('/api/models')
        .then(response => response.json())
        .then(data => {
            if (data.error) {
                modelStats.innerHTML = `<div class="alert alert-danger">${data.error}</div>`;
                return;
            }
            
            // Update currentModel display
            for (const [modelId, modelData] of Object.entries(data)) {
                if (modelData.is_current) {
                    currentModelDisplay.textContent = formatModelName(modelId);
                    break;
                }
            }
            
            // Build HTML for model stats
            let statsHtml = '';
            for (const [modelId, modelData] of Object.entries(data)) {
                const modelName = formatModelName(modelId);
                const successRate = (modelData.success_rate * 100).toFixed(1);
                const avgLatency = modelData.average_latency.toFixed(2);
                const totalCalls = modelData.total_calls;
                const isCurrent = modelData.is_current;
                
                statsHtml += `
                <div class="model-stat-card ${isCurrent ? 'current-model' : ''}">
                    <h6>${modelName} ${isCurrent ? '<span class="badge bg-success">Active</span>' : ''}</h6>
                    <div class="progress mb-2" style="height: 10px;">
                        <div class="progress-bar ${getSuccessRateClass(modelData.success_rate)}" 
                             role="progressbar" 
                             style="width: ${successRate}%;"
                             aria-valuenow="${successRate}" 
                             aria-valuemin="0" 
                             aria-valuemax="100">
                        </div>
                    </div>
                    <div class="model-stats-details">
                        <div><small>Success: ${successRate}%</small></div>
                        <div><small>Latency: ${avgLatency}s</small></div>
                        <div><small>Calls: ${totalCalls}</small></div>
                    </div>
                </div>
                `;
            }
            
            modelStats.innerHTML = statsHtml;
        })
        .catch(error => {
            modelStats.innerHTML = `<div class="alert alert-danger">Error loading model stats: ${error.message}</div>`;
        });
    }
    
    function formatModelName(modelId) {
        // Convert venice-large-beta to Venice Large
        return modelId
            .replace('venice-', '')
            .replace('-beta', '')
            .split('-')
            .map(word => word.charAt(0).toUpperCase() + word.slice(1))
            .join(' ');
    }
    
    function getSuccessRateClass(rate) {
        if (rate >= 0.85) return 'bg-success';
        if (rate >= 0.7) return 'bg-info';
        if (rate >= 0.5) return 'bg-warning';
        return 'bg-danger';
    }
    
    function truncateText(text, maxLength) {
        if (text.length <= maxLength) return text;
        return text.substring(0, maxLength) + '...';
    }
    
    // Image generation functionality
    const imageGenForm = document.getElementById('imageGenForm');
    const imagePrompt = document.getElementById('imagePrompt');
    const imageModel = document.getElementById('imageModel');
    const imageSize = document.getElementById('imageSize');
    const numImages = document.getElementById('numImages');
    const generateBtn = document.getElementById('generateBtn');
    const imageResults = document.getElementById('imageResults');
    const imageLoading = document.getElementById('imageLoading');
    
    // Load available image models
    fetch('/api/image-models')
        .then(response => response.json())
        .then(data => {
            if (data.error) {
                console.error("Error loading image models:", data.error);
                return;
            }
            
            if (data.models && data.models.length > 0) {
                // Clear default option
                imageModel.innerHTML = '';
                
                // Add available models
                data.models.forEach(model => {
                    const option = document.createElement('option');
                    option.value = model.id;
                    option.textContent = model.id;
                    imageModel.appendChild(option);
                });
            }
        })
        .catch(error => {
            console.error("Error fetching image models:", error);
        });
    
    // Handle image generation form submission
    imageGenForm.addEventListener('submit', function(e) {
        e.preventDefault();
        
        const prompt = imagePrompt.value.trim();
        if (!prompt) {
            alert('Please enter an image description');
            return;
        }
        
        // Show loading indicator
        imageLoading.classList.remove('d-none');
        imageResults.innerHTML = '';
        generateBtn.disabled = true;
        
        // Call the API
        fetch('/api/generate-image', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                prompt: prompt,
                model: imageModel.value,
                size: imageSize.value,
                num_images: parseInt(numImages.value)
            })
        })
        .then(response => response.json())
        .then(data => {
            // Hide loading indicator
            imageLoading.classList.add('d-none');
            generateBtn.disabled = false;
            
            if (data.error) {
                imageResults.innerHTML = `
                    <div class="alert alert-danger">
                        <i class="bi bi-exclamation-triangle-fill me-2"></i>
                        Error: ${data.error}
                    </div>
                `;
                return;
            }
            
            // Display the images
            let resultsHtml = `
                <div class="mb-3">
                    <h5>Generated with ${data.model_used}</h5>
                    <p class="text-muted small">Prompt: "${prompt}"</p>
                </div>
                <div class="row">
            `;
            
            data.images.forEach(image => {
                resultsHtml += `
                    <div class="col-md-${12 / data.images.length} mb-3">
                        <div class="card">
                            <img src="${image.url}" class="card-img-top" alt="Generated image">
                            <div class="card-body">
                                <a href="${image.url}" class="btn btn-sm btn-outline-primary" target="_blank">
                                    <i class="bi bi-download"></i> View Full Size
                                </a>
                            </div>
                        </div>
                    </div>
                `;
            });
            
            resultsHtml += '</div>';
            imageResults.innerHTML = resultsHtml;
        })
        .catch(error => {
            imageLoading.classList.add('d-none');
            generateBtn.disabled = false;
            
            imageResults.innerHTML = `
                <div class="alert alert-danger">
                    <i class="bi bi-exclamation-triangle-fill me-2"></i>
                    Error: ${error.message}
                </div>
            `;
        });
    });
});
</script>
{% endblock %}
